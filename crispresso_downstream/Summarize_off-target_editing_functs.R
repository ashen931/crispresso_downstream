#Summarize_off-target_editing_functs.R
# conda_environment: crispresso_downstream_env
# last modified: 2020_07_21 Anne Shen
# For use with CRISPResso version 2.0.37
#
### Dependencies:
# library(tidyverse)
# library(tidyselect)
# library(gtable)
# library(scales)
# library(gridExtra)
# library(grid)
# library(effsize)
# library(extrafont)
#
# font_import()
# loadfonts()
#
#
### Options:
# options(scipen=999) #turn off scientific notation
#
#
### Functions:
# summarize_off_targets()
#   remove_guideseq_from_cols()
#   get_formatted_summary()
#     get_group_summary_table()
#     get_table_by_guide()
#   pair_mock_v_edited_samples_by_donor()
#     get_stat_comparison_sample_tb()
#   get_ttest_table()
#   save_editing_results()
#   check_plot_aesthetics()
#     get_default_palette()
#   order_alpha()
#   get_aes_scale_values_for_dotplot()
#   get_heatmap_legend_values()
#   make_compiled_OT_editing_dotplot()
#   make_compiled_summary_OT_editing_boxplot()
#   make_compiled_OT_coverage_heatmap()
#   make_composite_grobPlot()
#   save_composite_plot()


######################################## FUNCTIONS ##################################################

###### summarize_off_targets() ##################################################################
# Function that generates all off-target analyses with the following steps:
#   1. format collapsed summary tables & read in metadata/reference tables
#   2. generate & format editing frequency & data tables
#   3. perform statistical tests (Mock v. Edited for each donor)
#   4. generate aesthetics for editing dotplot
#   5. generate all plots (editing dotplot, read coverage heatmap, composite plot)
#
# CALLS HELPERS: remove_guideseq_from_cols(), get_formatted_summary(), pair_mock_v_edited_samples_by_donor(),
#                get_ttest_table(), save_editing_results(), check_plot_aesthetics(), order_alpha(),
#                get_aes_scale_values_for_dotplot(), make_compiled_OT_editing_dotplot(),
#                make_compiled_OT_coverage_heatmap(), make_composite_grobPlot(), save_composite_plot()
# CALLED IN: CRISPResso2_downstream.R
#
# ARGUMENTS:
#   mode = run mode (ex. "collapse_BE_OT", "BE_OT", "OT_only" etc.)
#   ref_seq_csv = csv name for reading in ref_seq_tb containing all reference, guide, and PAM sequences 
#                 by off-target
#   ot_sample_csv = name of ot_sample_csv file (contains donor, condition, CRISPResso_dir_name, sample_name)
#   percent_freq_cutoff = percent cutoff for alleles in alleles summary tables (generated by "collapse"
#                         mode)
#   scale_size_by_editing_freq = logical, whether or not to separate geom_points by size according to read coverage
#                                in the editing scatterplot
#   low_coverage = the upper read count cutoff for "low-coverage" amplicons/samples
#   high_coverage = the lower read count cutoff for "high-coverage" amplicons/samples
#
# OUTPUT:
#   1. saves ot_ttest_tb as "CRISPResso_OTs_ttest.csv"
#   2. saves edited_summary_tb as "CRISPResso_OT_editing_summary.csv"
#   3. saves off-target composite figures as .pdf and .png 
summarize_off_targets <- function(mode, ref_seq_csv, ot_sample_csv, percent_freq_cutoff,
                                  conversion_nuc_from, conversion_nuc_to,
                                  scale_size_by_editing_freq, low_coverage, high_coverage){
  
  #test code:
  # saved_wd <- getwd()
  # setwd("/Users/anneshen/Documents/local_working/local_Jing_BE/1620/20200711_1620_ONESeq_rhAMPSeq_triplicates")
  # mode<- "BE_OT"
  # ref_seq_csv <- "1620_ONESeq_ref_seqs.csv"
  # ot_sample_csv<- "20200711_1620_rhAMPSeq_samples.csv"
  # percent_freq_cutoff <- 0
  # conversion_nuc_from <- "C"
  # conversion_nuc_to <- "T"
  # scale_size_by_editing_freq <- TRUE
  # low_coverage <- 1000
  # high_coverage <- 10000
  # 
  # setwd("/Users/anneshen/Documents/local_working/IND_off_target/2020_CRISPResso2/20200722_DE_1450_rhAMPSeq")
  # mode<- "OT_only"
  # ref_seq_csv <- "202006_1450_0000_ref_seqs.csv"
  # ot_sample_csv<- "202006_DE_1450_rhAMPSeq_samples.csv"
  # percent_freq_cutoff <- 0
  # scale_size_by_editing_freq <- TRUE
  # low_coverage <- 1000
  # high_coverage <- 10000
  
  cat("Off_target_summary_log\n",
      paste(Sys.time(), "\n", sep = ""),
      paste(getwd(), "\n", sep = ""),
      "ref_seq_csv: ", ref_seq_csv, "\n",
      "ot_sample_csv: ", ot_sample_csv, "\n",
      "percent_freq_cutoff: ", percent_freq_cutoff, "\n",
      "analysis_mode: ", mode, "\n",
      "scale_size_by_editing_freq: ", scale_size_by_editing_freq, "\n", 
      "low_coverage: ", low_coverage, "\n",
      "high_coverage: ", high_coverage, "\n",
      "\n")
  
  #set date for saving figures
  date <- format(Sys.Date(), "%Y%m%d")
  
  ##### 1. format collapsed summary tables & read in metadata/reference tables ##### 
  
  #get all summary file names
  if(grepl("BE", mode)){
    
    #if running OT analysis on base editing data, use BE summary tables
    conversion <- paste(conversion_nuc_from, "to", conversion_nuc_to, ".csv", sep = "")
    summary_file_suffix <- paste("BE_summary_", conversion, sep = "")
    # ADDED
    # list_summary_files <- list.files(pattern = paste("BE_summary_", conversion_nuc_from, "to", 
    #                                                   conversion_nuc_to,".csv", sep = ""))
    list_summary_files <- list.files(pattern = summary_file_suffix)
    
    # ADDED
    #get BE conversion file suffix
    #conversion <- regmatches(list_summary_files[1], regexpr("[ATCG]{1}to[ATCG]{1,}.csv", list_summary_files[1]))
    
  }else{
    #get collapsed file suffix
    summary_file_suffix <- paste("collapsed_", percent_freq_cutoff, ".csv", sep = "")
    
    #if not running OT analysis on base editing data, use collapsed allele tables
    list_summary_files <- list.files(pattern = summary_file_suffix)
  }
  
  #read in ref_seq_tb linking off-target names and sequences
  ref_seq_tb <- read.csv(ref_seq_csv, stringsAsFactors = FALSE) %>%
    filter(grepl("OT", ot_id)) %>%
    rename(off_target = ot_id) %>%
    filter(!duplicated(off_target))
  
  #Remove guide name from list_summary_files file columns (only need to do once) & re-saves .csv file.
  # Also separates guides on the same amplicon.
  # Non-fruitful function
  remove_guideseq_from_cols(list_summary_files, ref_seq_tb, ref_seq_csv)
  
  #read in sample table
  ot_samples_tb <- read.csv(ot_sample_csv, stringsAsFactors = FALSE)
  #get ot_samples_tb row indexes for mock & experimental samples
  mock_samples_idx <- grep("mock", ot_samples_tb$condition, ignore.case = TRUE)
  trt_samples_idx <- grep("mock", ot_samples_tb$condition, ignore.case = TRUE, invert = TRUE)
  
  
  
  
  ##### 2. generate & format editing frequency & data tables ##### 
  
  #get editing tables from mock_sample collapsed/filtered allele tables
  all_mock_tb <- get_formatted_summary(ot_samples_tb, mock_samples_idx, summary_file_suffix,
                                       ref_seq_tb, condition = "control")

  #get editing tables from experimental_sample collapsed/filtered allele tables
  all_trt_tb <- get_formatted_summary(ot_samples_tb, trt_samples_idx, summary_file_suffix, 
                                      ref_seq_tb, condition = "edited")

  #bind all data tables together by columns
  all_samples_from_file <- rbind(all_mock_tb, all_trt_tb)
  
  
  #generate all_samples table (complete table including all off-target and all samples)
  unique_samples_idx <- unique(all_samples_from_file$sample)
  unique_samples <- unique_samples_idx[which(!is.na(unique_samples_idx))]
  n_control <- length(mock_samples_idx)
  n_edited <- length(trt_samples_idx)
  n_samples <- n_control + n_edited
  
  all_samples <- data.frame(off_target = rep(ref_seq_tb$off_target, times = n_samples, each = 2),
                            amplicon_sequence = rep(ref_seq_tb$amplicon_sequence, times = n_samples, each = 2),
                            guide_sequence = rep(ref_seq_tb$guide_sequence, times = n_samples, each = 2),
                            pam = rep(ref_seq_tb$pam, times = n_samples, each = 2),
                            indel = rep(c("Unedited", "Edited"), nrow(ref_seq_tb) * n_samples),
                            sample = rep(c(unique_samples), times = 1, each = nrow(ref_seq_tb) * 2),
                            condition = rep(c(rep("control", n_control), rep("edited", n_edited)), times = 1, 
                                            each = nrow(ref_seq_tb) * 2))
  
  #join all_samples & all_samples_from_file to get table with all off-targets and samples represented
  # (NAs for frequencies and reads of samples that were not analyzed in CRISPResso2)
  all_samples_tb <- left_join(all_samples, all_samples_from_file, by = names(all_samples)) %>%
    mutate(group = paste(condition, sample, sep = " "))
  
  #generate name_seq column (OT name + guide sequence + PAM) with standardized spacing
  max_nseq_len <- max(str_length(all_samples_tb $off_target) + 
                        str_length(all_samples_tb $guide_sequence))
  all_samples_tb  <- all_samples_tb  %>%
    mutate(padding = as.numeric(max_nseq_len - str_length(off_target) - str_length(guide_sequence))) 
  all_samples_tb$spaces <- str_dup(rep(" ", nrow(all_samples_tb )), all_samples_tb $padding)
  all_samples_tb$name_seq <- paste(paste(all_samples_tb $off_target, 
                                          " ",
                                          all_samples_tb $spaces,
                                          all_samples_tb $guide, sep = ""),
                                    all_samples_tb $pam, sep = " ")
  #remove unnecessary columns
  all_samples_tb  <- all_samples_tb  %>%
    select(-c("padding", "spaces"))
  
  #select only off-targets & samples that were represented in CRISPResso2 analysis
  # (will not include off-targets with no samples in final composite figure)
  all_samples_tb <- all_samples_tb[complete.cases(all_samples_tb), ]
  
  #select data representing editing frequency
  edited_summary_tb <- all_samples_tb %>%
    filter(indel == "Edited") %>%
    select(-amplicon_sequence)
  
  
  
  ##### 3. perform statistical tests (Mock v. Edited for each donor) ##### 
  
  ### statistical test
  # Compare % edited in Mock v. Edited samples
  paired_stats_tb <- pair_mock_v_edited_samples_by_donor(ot_sample_csv)

  #get list of off-targets
  off_targets <- unique(edited_summary_tb$off_target)
  
  #generate table of Edited v. Mock editing frequency results
  ot_ttest_tb <- get_ttest_table(off_targets, edited_summary_tb, paired_stats_tb)
  sig_ots <- ot_ttest_tb$off_target[which(ot_ttest_tb$significant)] %>% droplevels()
  
  #save OT ttest statistics as csv
  write.csv(ot_ttest_tb, paste(date, "CRISPResso_OTs_ttest.csv", sep = "_"), 
            row.names = FALSE, quote = FALSE)
  
  #add asterisks (*) to name_seq of significant off-targets
  for(n in seq(1, nrow(edited_summary_tb))){
    
    edited_summary_tb$name_seq <- as.character(edited_summary_tb$name_seq)
    
    if(edited_summary_tb$off_target[n] %in% sig_ots){
      edited_summary_tb$name_seq[n] <- paste(edited_summary_tb$name_seq[n],
                                             "* ", 
                                             sep = " ")
    }else{
      edited_summary_tb$name_seq[n] <- paste(edited_summary_tb$name_seq[n],
                                             "  ", 
                                             sep = " ")
    }
  }
  
  #format editing results and save as csv file (non-fruitful function)
  save_editing_results(date, edited_summary_tb)
  
  
  
  ##### 4. set 0% editing frequency to power of 10 below lowest frequency (for plotting purposes) ##### 
  
  #find the lowest editing % frequency in all the samples, then go a power of 10 below that minimum 
  # for the "0% editing" setting on the composite % editing scatterplot 
  min_edited_log_freq <- min(edited_summary_tb$log_freq[which(edited_summary_tb$log_freq > -Inf)])
  power10_floor <- floor(min_edited_log_freq) - 1
  
  
  #set all 0% editing to 10^power10_floor (for log10 transformation)
  zero_freq_row_idx <- which(edited_summary_tb$frequency == 0)
  edited_summary_tb$frequency[zero_freq_row_idx] <- 10^power10_floor
  edited_summary_tb$log_freq[zero_freq_row_idx] <- power10_floor
  
  
  
  ##### 5. generate aesthetics for editing dotplot ##### 
  
  #get aesthetics columns from ot_samples_tb to join with edited_summary_tb
  aes_tb <- select(ot_samples_tb, c("condition", "sample_name", grep("R_", names(ot_samples_tb), value = TRUE)))
  
  #check that R_color, R_fill, and R_shape aesthetics exist & generate defaults if non-existent
  aes_tb <- check_plot_aesthetics(aes_tb)
  
  #join aes_tb with edited_summary_tb to match aesthetics scale values with samples for plotting
  full_plotting_tb <- full_join(edited_summary_tb, select(aes_tb, -condition), by = c("sample" = "sample_name")) %>%
    order_alpha("off_target", decreasing_bool = FALSE)
  
  #get list of dotplot aesthetics scale values (color, fill, shape)
  aes_val_list <- get_aes_scale_values_for_dotplot(full_plotting_tb)
  
  #generate counts total counts table
  full_total_counts_tb <- all_samples_tb %>%
    filter(indel == "Unedited" ) %>%
    mutate(total_reads = ceiling((reads * 100) / frequency ))
  
  
  ##### 6. calculate number of OTs per plot and aesthetics sizes ##### 
  
  #use the following data frame to calculate the number of plots to generate (between 20-60 OTs per plot)
  n_targets <- length(unique(full_plotting_tb$off_target))
  ots_per_plot_df <- data.frame(ots_per_plot = seq(20, 60, 10)) %>%
    mutate(min_n_plots = n_targets %/% ots_per_plot,
           ots_rem = n_targets %% ots_per_plot,
           diff_ots_per_plot = ots_per_plot - ots_rem)
  
  #choose to plot the least number of plots with the most even distribution of off-targets among plots
  min_idx <- max(which(ots_per_plot_df$diff_ots_per_plot == min(ots_per_plot_df$diff_ots_per_plot)))
  n_ots_per_plot <- ots_per_plot_df$ots_per_plot[min_idx]
  unique_ots <- levels(full_plotting_tb$off_target)
  
  #adjust font sizes according to number of off-targets displayed per plot
  guide_font_size <- 10 - (n_ots_per_plot %/% 30) 
  tile_font_size <- 2.75 - (n_ots_per_plot %/% 30)*0.25
  pointsize <- 1.5 - (n_ots_per_plot %/% 30)*0.25
  group_font_size <- 8 - (n_ots_per_plot %/% 10)*0.25
  
  #adjust heatmap and dotplot width to match sample number
  n_plot_samples <- length(unique(full_plotting_tb$sample))
  heatmap_width <- n_plot_samples * 0.5 + 2
  dotplot_width <- n_plot_samples * 0.05 + 8
  cplot_height <- n_plot_samples * 0.1 + 8.5 
  
  #Generate legend values for all figures. Calculate the best legend label increments such that:
  # -there are at >= 5 labels
  # -the labels encompass 10^(max_log10 - 1) to at least the max_reads
  legend_breaks <- get_heatmap_legend_values(full_total_counts_tb$total_reads)
  
  #generate editing % frequency scatterplot scale (to go from 10^power10_floor --> 100)
  # (power10_floor = log10(lowest editing % frequency) -1)
  editing_freq_scale <- mapply(function(x) 10^x, seq(power10_floor, 2))
  
  #add total_reads column to plotting_tb
  full_plotting_tb <- full_join(full_plotting_tb, full_total_counts_tb[c("off_target", "group", "total_reads")],
                           by = c("off_target", "group"))
  
  #add geom_point size column (R_point_size) if scale_size_by_editing_freq == TRUE & generate aesthetics list
  if(scale_size_by_editing_freq){
    
    #set medium and high-coverage points
    mid_coverage_size <- pointsize + 0.6
    high_coverage_size <- pointsize + 1.5
    
    full_plotting_tb$R_point_size <- as.factor(ifelse(full_plotting_tb$total_reads < low_coverage, pointsize,
                                                 ifelse(full_plotting_tb$total_reads <= high_coverage, mid_coverage_size, 
                                                        high_coverage_size)))
    #generate aesthetics list
    size_range <- c(pointsize, high_coverage_size)
    size_val <- c(pointsize, mid_coverage_size, high_coverage_size)
    names(size_val) <- as.factor(c(pointsize, mid_coverage_size, high_coverage_size))
    size_lab <- c(paste("<", low_coverage, " reads", sep = ""), 
                  paste(low_coverage,"-", high_coverage, " reads", sep = ""),
                  paste(">", high_coverage, " reads", sep = ""))
    names(size_lab) <- as.factor(c(pointsize, mid_coverage_size, high_coverage_size))
    aes_val_list$size_scale_val <- list("Read\nCoverage", size_val, size_lab)
    
  }else{
    full_plotting_tb$R_point_size <- pointsize
    aes_val_list$size_scale_val <- NULL
  }


  
  
  ##### 7. generate all plots (editing dotplot, read coverage heatmap, composite plot) ##### 
  
  #initialize while loop iterator
  ots_plotted <- 0
  #initialize plot number tracker
  n_plots <- 0
  
  #initialize composite plot list for pdf printing
  composite_plot_list <- list()
  
  #generate the plots
  while(ots_plotted < n_targets){
    
    #increase plot number iterator
    n_plots <- n_plots + 1
    
    #calculate the number of off-targets to include the current plot
    n_ots_this_plot <- min(n_targets - ots_plotted, n_ots_per_plot)
    
    
    #get the total counts for the plotted off_targets
    total_counts <-  full_total_counts_tb %>%
      filter(off_target %in% unique_ots[(ots_plotted + 1):(ots_plotted + n_ots_this_plot)]) %>%
      order_alpha("name_seq", decreasing_bool = FALSE)
    
    #order the sample names so that samples are listed by donor
    heatmap_sample_order <- ot_samples_tb$sample_name[str_order(ot_samples_tb$donor, numeric = TRUE)]
    heatmap_group_idx <- mapply(function(x) which(total_counts$sample == x )[1] , heatmap_sample_order)
    total_counts$group <- factor(total_counts$group, levels = total_counts$group[heatmap_group_idx])
    
    #generate coverage heatmap 
    heatmap <- make_compiled_OT_coverage_heatmap(total_counts, guide_font_size, 
                                                 group_font_size, tile_font_size,
                                                 legend_breaks)
    
    
    
    #filter full_plotting_tb to include only off-targets in the current plot
    plotting_tb <- full_plotting_tb %>%
      filter(off_target %in% unique_ots[(ots_plotted + 1):(ots_plotted + n_ots_this_plot)]) %>%
      order_alpha("name_seq", decreasing_bool = FALSE) 
    
    #### generate editing dotplot
    dotplot <- make_compiled_OT_editing_dotplot(plotting_tb, scale_size_by_editing_freq,
                                                aes_val_list$fill_scale_val, 
                                                aes_val_list$color_scale_val, 
                                                aes_val_list$shape_scale_val, 
                                                aes_val_list$size_scale_val,
                                                guide_font_size, editing_freq_scale)
    
    summary_dotplot <- make_compiled_summary_OT_editing_boxplot(plotting_tb,
                                                                guide_font_size, 
                                                                editing_freq_scale)
    
    #make and save composite plots
    composite_plot <- make_composite_grobPlot(heatmap, dotplot, heatmap_width, dotplot_width)
    summary_composite_plot <- make_composite_grobPlot(heatmap, summary_dotplot, heatmap_width, dotplot_width)
    
    #save composite plots as individual png files
    png_plot_name <- paste(date, "off_targets_Rplot", n_plots , sep = "_")
    save_composite_plot(png_plot_name, composite_plot, heatmap_width + dotplot_width + 1, cplot_height + 1)
    #save summary plots
    png_summary_plot_name <- paste(date, "off_targets_summary_Rplot", n_plots , sep = "_")
    save_composite_plot(png_summary_plot_name, summary_composite_plot, 
                        heatmap_width + dotplot_width + 1, cplot_height + 1)
    
    #add composite plot to list for printing in pdf
    composite_plot_list[[n_plots]] <- composite_plot
    
    #record plotting in run log
    cat("targets plotted in ", png_plot_name, ": ", ots_plotted+1, " - ", ots_plotted + n_ots_this_plot, "\n")
    
    #increase iterators
    ots_plotted <- ots_plotted + n_ots_this_plot
  }
  
  #printing composite plots in single .pdf file
  pdf(file = paste(date, "off_targets_Rplot.pdf", sep = "_"), onefile = TRUE, 
      width = heatmap_width + dotplot_width + 1, height = cplot_height + 1)
  #print composite plots
  for(i in 1:length(composite_plot_list)){
    print(composite_plot_list[[i]])
  }
  #disconnect device for pdf printing
  dev.off()
  
  #end off-target analysis log
  cat("\n")
}



###### remove_guideseq_from_cols() ##################################################################
# Reads through the collapsed files (generated either in "collapse" or "BE" mode) in list_summary_files 
# and removes the guide sequences from the column headers. Also resolves cases where multiple guides
# were found in the same amplicon; this function renames the column headers by guide, not amplicon.
# Immediately throws an error if the guide_sequences in ref_seq_tb are not unique. (Repeated guides will 
# cause errors in table joining later in the function.)
#
# CALLS HELPERS: NA
# CALLED IN: summarize_off_targets()
#
# ARGUMENTS:
#   list_summary_files = list of collapsed or BE allele summary files
#   ref_seq_tb = table containing all reference, guide, and PAM sequences by off-target
#   ref_seq_csv= csv name for reading in ref_seq_tb 
#
# OUTPUT: none
remove_guideseq_from_cols <- function(list_summary_files, ref_seq_tb, ref_seq_csv){
  
  # setwd("/Users/anneshen/Documents/local_working/IND_off_target/2020_CRISPResso2/20200722_DE_1450_rhAMPSeq")
  # ref_seq_csv <- "202006_1450_0000_ref_seqs.csv"
  # ref_seq_tb <- read.csv(ref_seq_csv, stringsAsFactors = FALSE) %>%
  #   rename(off_target = ot_id)
  # list_summary_files <- list.files(pattern = "collapse")
  
  # setwd("/Users/anneshen/Documents/local_working/local_Jing_BE/1620/20191206_1620_input_rhAMPSeq_integrated3")
  # ref_seq_csv <- "1620_ref_seqs_tb.csv"
  # ref_seq_tb <- read.csv(ref_seq_csv, stringsAsFactors = FALSE) %>%
  #   rename(off_target = ot_id)
  # list_summary_files <- list.files(pattern = "collapse")

  #remove guide name from list_summary_files file columns (only need to do once)
  # Also separates guides on the same amplicon.
  for(file in list_summary_files){

    temp <- read.csv(file, stringsAsFactors = FALSE)
    
    #remove guide sequence from column name if not removed already
    if(any(grepl("__[ATCG]{6,}", names(temp)))){
      renaming_df <- data.frame(sample_names = grep("__", names(temp), value = TRUE))%>%
        separate(col = sample_names, into = c("sample", "guide"), sep = "__", remove = FALSE)
      
      #order of sample_names is retained
      joined_df <- left_join(renaming_df, ref_seq_tb, by = c("guide" = "aligned_guide_seq")) %>%
        mutate(filter = str_detect(sample, off_target)) %>%
        filter(filter) %>%
        transform(off_target = ifelse(grepl("read", sample), paste(off_target, "reads", sep = "_"), off_target)) %>%
        select(-filter)
      
      #rename the columns of temp to be the off_target name
      names(temp)[grep("__", names(temp))] <- as.character(joined_df$off_target)
      
      write.csv(temp, file = file, row.names = FALSE)
    }
  }
}


###### get_formatted_summary() ##################################################################
# For either all the control or edited samples, reads all the allele frequency tables (generated either
# during the "collapse" or "BE" modes), summarizes the Edited v. Unedited allele frequencies for each
# target within each sample, and formats all the data within one data frame.
#
# CALLS HELPERS: get_group_summary_table()
# CALLED IN: summarize_off_targets()
#
# ARGUMENTS:
#   ot_samples_tb = sample metadata table containing donor, condition, CRISPResso_dir_name, and sample_name
#   ot_sample_idx = vector of desired samples' row indexes in ot_samples_tb
#   summary_file_suffix = suffix of all allele collapsed summary tables (depends on whether 
#                         "collapsed" or "BE" mode was used to generate most recent summary table)
#   master_guide_tb = table containing all reference, guide, and PAM sequences by off-target
#   condition = desired condition to samples in this table (either "control" or "edited")
#
# OUTPUT:
#   summary_and_seq_tb = full data table containing Edited/Unedited frequencies of every off-target
#                        of every CRISPResso2 run/sample
get_formatted_summary <- function(ot_samples_tb, ot_sample_idx, summary_file_suffix,
                                  master_guide_tb, condition){
  
  #loop through all the summary files
  for(n in seq(1, length(ot_sample_idx))){
    
    #get idx of CRISPResso2 sample name in ot_samples_tb
    idx <-ot_sample_idx[n]
    
    #get the sample file names & read in summary tables
    summary_file_name <- paste(ot_samples_tb$CRISPResso_dir_name[idx], summary_file_suffix, sep = "_")
    summary_tb_raw <- read.csv(summary_file_name, stringsAsFactors = FALSE)
    
    #get the sample name of the CRISPResso2 run
    sample_name <- ot_samples_tb$sample_name[idx]
    
    #for all off-targets in the CRISPResso2 run, obtain "Edited" and "Unedited" total allele frequencies
    summary_tb <- get_group_summary_table(summary_tb_raw, sample_name)
    
    #gather columns into off_target and read columns
    summary_table_reads <-summary_tb %>%
      select(vars_select(names(summary_tb), -matches("[0-9]$"))) %>%
      gather(key = "off_target", value = "reads", 
             vars_select(names(summary_tb), contains("_reads")))
    
    summary_table_reads$off_target <- gsub("_reads", "", summary_table_reads$off_target)
    
    #gather columns into off_target and read columns
    summary_table_freqs <- summary_tb %>% 
      select(vars_select(names(summary_tb), -ends_with("_reads"))) %>%
      gather(key = "off_target", value = "frequency",
             vars_select(grep("_reads", names(summary_tb), invert = TRUE, value = TRUE),
                         contains("_O")))
    
    summary_table <-full_join(summary_table_freqs, summary_table_reads, 
                              by =c("off_target", "indel", "sample"))
    
    if(n == 1){
      all_summary_table <- summary_table
    }else{
      all_summary_table <- rbind(all_summary_table, summary_table)
    }
  }
  
  #add off-target sequence to summary table
  summary_and_seq_tb <- left_join(master_guide_tb, all_summary_table, by = "off_target")
  
  #log10 transform frequency
  summary_and_seq_tb$log_freq <- log10(summary_and_seq_tb$frequency)
  
  #order table by off_target
  summary_and_seq_tb <- summary_and_seq_tb[order(summary_and_seq_tb$off_target),]
  
  #add "condition" column to indicate whether this was an edited or control sample
  summary_and_seq_tb$condition <- rep(condition, nrow(summary_and_seq_tb))
  
  return(summary_and_seq_tb)
}



###### get_group_summary_table() ##################################################################
# For all off-targets in a CRISPResso2 run, obtains "Edited" and "Unedited" total allele frequencies.
#
# CALLS HELPERS: NA
# CALLED IN: get_formatted_summary()
#
# ARGUMENTS:
#   pool_tb = collapsed allele table generated by "collapse" mode (read in from file name)
#   sample_name = name of user-input CRISPResso2 run sample from ot_sample_csv file
#
# OUTPUT:
#   pool_summary = table containing % edited and unedited alleles for all off-targets in CRISPResso run
get_group_summary_table <- function(pool_tb, sample_name){
  
  #vector of fixed pool_tb headers
  fixed_col_names <- c("Aligned_Sequence", "Reference_Sequence", "Unedited", "n_deleted", 
                       "n_inserted", "n_mutated", "indel")
  
  #remove "X" from beginning of off-target names (column headers) if they begin with numbers or 
  # special symbols 
  names(pool_tb) <- gsub("^X", "", names(pool_tb))
  
  #get table with total Unedited frequency across all off-targets within CRISPResso sample/run
  unedited <- pool_tb %>% 
    filter(indel == "Unedited") %>%
    select(which(! names(pool_tb) %in% fixed_col_names)) %>%
    mutate(indel = "Unedited", sample = sample_name)
  
  #get table with total Edited frequency across all off-targets within CRISPResso sample/run
  edited <- pool_tb %>% 
    filter(indel != "Unedited") %>%
    select(which(! names(pool_tb) %in% fixed_col_names))%>%
    colSums(na.rm = TRUE)
  
  #bind edited & unedited data together
  pool_summary <- rbind(unedited, edited) 
  
  #rename edited indel and sample appropriately
  pool_summary$indel[2] <- "Edited"
  pool_summary$sample[2] <- sample_name
  
  return(pool_summary)
}



###### pair_mock_v_edited_samples_by_donor() ##################################################################
# Reads in ot_sample_csv table and adds a column complete_for_stats indicated whether each donor has both
# edited and mock CRIPSResso2 samples (ready for statistics). Each row contains mock & edited sample pairings
# by donor (if a donor has 1 mock and 2 edited samples, the mock will be repeated in 2 rows and paired 
# with a different edited sample in each row).
#
# CALLS HELPERS: get_stat_comparison_sample_tb()
# CALLED IN: summarize_off_targets()
#
# ARGUMENTS:
#   ot_sample_csv = name of ot_sample_csv file (contains donor, condition, CRISPResso_dir_name, sample_name)
#
# OUTPUT:
#   donor_paired_tb = table containing "mock" and "edited" sample columns in which rows contain paired
#                     samples by donor (sets of samples appropriate for statistical analyses)
pair_mock_v_edited_samples_by_donor <- function(ot_sample_csv){
  
  #filter table for just donors with samples available for statistical comparison
  stat_comp_tb <- get_stat_comparison_sample_tb(ot_sample_csv)
  
  #get list of unique donors for statistical comparison
  unique_donors <- unique(stat_comp_tb$donor)
  
  # pair donor/mock in donor_paired_tb
  donor_paired_tb <- data.frame(donor = as.character(c()), mock = as.character(c()), edited = as.character(c()),
                                stringsAsFactors=FALSE)
  
  #for each donor that has both mock and edited samples
  for(donor in unique_donors){
    
    #get the names of the donor's samples
    donor_mock_samples <- stat_comp_tb[stat_comp_tb$donor == donor & grepl("mock", stat_comp_tb$condition),]$sample_name#[mock_samples_idx]
    donor_trt_samples <- stat_comp_tb[stat_comp_tb$donor == donor & !grepl("mock", stat_comp_tb$condition), ]$sample_name#[trt_samples_idx]
    
    n_mock_samples <- length(donor_mock_samples)
    n_trt_samples <- length(donor_trt_samples)
    
    #generate the donor-edited sample pairings (redundancy allowed)
    donor_paired_samples <- data.frame(donor = as.character(rep(donor, times = n_mock_samples*n_trt_samples)),
                                       mock = as.character(rep(donor_mock_samples,
                                                               each = n_trt_samples)),
                                       edited = as.character(rep(donor_trt_samples,
                                                                 times = n_mock_samples)),
                                       stringsAsFactors = FALSE)
    
    donor_paired_tb <- rbind(donor_paired_tb, donor_paired_samples)
  }
  
  donor_paired_tb <- donor_paired_tb %>%
    mutate(sample = paste(donor, row.names(donor_paired_tb), sep = "_"))
  
  return(donor_paired_tb)
}

###### get_stat_comparison_sample_tb() ##################################################################
# Reads in ot_sample_csv table and adds a column complete_for_stats indicated whether each donor has both
# edited and mock CRIPSResso2 samples (ready for statistics).
#
# CALLS HELPERS: NA
# CALLED IN: pair_mock_v_edited_samples_by_donor()
#
# ARGUMENTS:
#   ot_sample_csv = name of ot_sample_csv file (contains donor, condition, CRISPResso_dir_name, sample_name)
#
# OUTPUT:
#   sample_metadata = sample metadata table containing complete_for_stats column
get_stat_comparison_sample_tb <- function(ot_sample_csv){
  
  #read sample metadata table
  sample_metadata <- read.csv(file = ot_sample_csv, stringsAsFactors = FALSE)
  
  #get list of donors with associated mock sample
  donors_with_mock <- sample_metadata$donor[which(grepl("mock", sample_metadata$condition, 
                                                        ignore.case = TRUE))]
  #get list of donors with associated edited sample
  donors_with_edited <- unique(sample_metadata$donor[ which( !grepl( "mock", sample_metadata$condition, 
                                                                      ignore.case = TRUE))])
  #get list of donors with both mock and edited samples
  donors_complete <- intersect(donors_with_mock, donors_with_edited)
  
  #add complete_for_stats column to indicate whether a donor has both mock and edited conditions
  sample_metadata <- sample_metadata %>%
    mutate(complete_for_stats = ifelse(donor %in% donors_complete, TRUE, FALSE))
  
  return(sample_metadata)
}



###### get_ttest_table() ##################################################################
#Takes a list of unique off-target names and edited summary table and performs a t-test
# comparing the mean editing frequency between Edited and Mock samples. Because all mock & edited samples
# are paired by donor, all Mocks are averaged (and all Edited samples are averaged) for t.test calculations.
# This does mean that some samples are represented twice (ex. Mock1 is represented twice if both Edited1 
# and Edited2 are from the same donor and thus paired with Mock1.)
# Returns a table of off-targets and their corresponding t-test p-values, as well as whether the 
# difference between Edited and Mock is significant.
# (NOTE: statistical comparison is ONLY performed for donors with AT LEAST one mock and one edited sample.
#  Comparisons are skipped where there is only one Edited or Mock sample available for the target across
#  donors.)
#
# CALLS HELPERS: NA
# CALLED IN: summarize_off_targets()
#
# ARGUMENTS:
#   off_targets = list of off-targets for statistical comparison
#   edited_summary_tb = summary table of off-target editing frequencies
#   paired_stats_tb = table storing mock-edited sample pairings for each donor appropriate for statistical
#                     comparisons
#
# OUTPUT: 
#   ots_pval_tb = table showing median & mean editing frequencies for mock and edited samples as well as 
#                 the p-value of the one-tailed t.test (alpha = 0.05) comparison and effect size
#                 (ordered by off-target)
get_ttest_table <- function(off_targets, edited_summary_tb, paired_stats_tb){
  
  #initalize p-value vector
  p_vals <- c()
  #initalize effect size vector
  d_vals <- c()
  #initalize median vectors
  control_median <- c()
  edited_median <- c()
  #initalize mean vectors
  control_mean <- c()
  edited_mean <- c()
  #initalize sd vectors
  control_sd <- c()
  edited_sd <- c()
  
  #calculate p-values with t-test comparing Mock v. Edited samples for each off-target
  for(n in seq(1, length(off_targets))){
    
    #get rows that correspond with the off-target of interest
    ot_only_tb <- edited_summary_tb %>% 
      filter(complete.cases(edited_summary_tb)) %>%
      filter(off_target == off_targets[n])
    
    edited_freq <-ot_only_tb[ot_only_tb$sample %in% paired_stats_tb$edited,]$frequency
    control_freq <-ot_only_tb[ot_only_tb$sample %in% paired_stats_tb$mock,]$frequency
    
    #calculate median
    edited_median <- c(edited_median, median(edited_freq, na.rm = TRUE))
    control_median <- c(control_median, median(control_freq, na.rm = TRUE))
    
    #calculate mean
    ot_edited_mean <- mean(edited_freq, na.rm = TRUE)
    ot_control_mean <- mean(control_freq, na.rm = TRUE)
    edited_mean <- c(edited_mean, ot_edited_mean)
    control_mean <- c(control_mean, ot_control_mean)
    
    #calculate standard deviation
    ot_edited_sd <- sd(edited_freq, na.rm = TRUE)
    ot_control_sd <- sd(control_freq, na.rm = TRUE)
    edited_sd <- c(edited_sd, ot_edited_sd)
    control_sd <- c(control_sd, ot_control_sd)
    
    #check that there is sufficient variance and 
    if( any(edited_freq != control_freq) & (length(edited_freq) > 1) & (length(control_freq) > 1) ){
      
      #assuming edited_freq is larger than control_freq
      p_vals <- c(p_vals, 
                  t.test(edited_freq, control_freq, alternative = "greater", paired = FALSE)$p.value)
      
      #calculate cohen's d
      pooled_sd <- sqrt(( ot_edited_sd^2 + ot_control_sd^2 ) / 2)
      cohen_d <- ( ot_edited_mean - ot_control_mean ) / pooled_sd
      d_vals <- c(d_vals, cohen_d)

    }else{
      p_vals <- c(p_vals, NA)
      d_vals <- c(d_vals, NA)
    }

  }
  
  #generate data frame with off_targets, the t-test p-value associated with it,
  # and boolean (significant or not)
  ots_pval_tb <- data.frame(off_target = off_targets, 
                            edited_median = edited_median,
                            control_median = control_median,
                            edited_mean = edited_mean,
                            control_mean = control_mean,
                            edited_sd = edited_sd,
                            control_sd = control_sd,
                            ttest_p_value = p_vals,
                            eff_size = d_vals) %>%
    mutate(significant = ttest_p_value < 0.05)
  
  return(ots_pval_tb[order(ots_pval_tb$off_target),])
}


###### save_editing_results() ##################################################################
# Formats and saves off-target editing frequency table
#
# CALLS HELPERS: NA
# CALLED IN: summarize_off_targets()
#
# ARGUMENTS:
#   date = date in YYYYMMDD format
#   edited_summary_tb = summary table of off-target editing frequencies to be formatted and saved
#
# OUTPUT: none
save_editing_results <- function(date, edited_summary_tb){
  #format editing results
  edited_summary_tb_csv <- edited_summary_tb %>%
    rename(editing_freq = frequency) %>%
    order_alpha("name_seq", decreasing_bool = TRUE) %>%
    select(-c(log_freq, indel, name_seq))
  
  write.csv(edited_summary_tb_csv, paste(date, "CRISPResso_OT_editing_summary.csv", sep = "_"),
            row.names = FALSE)
}


###### check_plot_aesthetics() ##################################################################
# Check whether aesthetics (color, fill, shape) values have been entered by the user for editing dotplot
# generation. If not, fill in table with default aesthetics scale values.
#
# CALLS HELPERS: get_default_palette()
# CALLED IN: summarize_off_targets()
#
# ARGUMENTS:
#   aes_tb = data frame storing aesthetics (color, fill, shape) to be used for the dotplot
#
# OUTPUT:
#   aes_tb = aes_tb with default color, fill, and shape values (unless user had entered values)
check_plot_aesthetics <- function(aes_tb){
  
  #check that R_color, R_fill, and R_shape aesthetics exist & generate defaults if non-existent
  if(! "R_color" %in% names(aes_tb)){
    #get custom palette
    default_palette <- get_default_palette()
    
    #set default colors
    aes_tb$R_color <- default_palette[1:nrow(aes_tb)]
  }
  
  if(! "R_fill" %in% names(aes_tb)){
    #defaults as same colors as R_color
    aes_tb$R_fill <- aes_tb$R_color
  }
  
  if(! "R_shape" %in% names(aes_tb)){
    #determine which samples are mock in aes_tb
    is_mock <- aes_tb$condition == "mock"
    
    #set defaults: control/mock is 1, edited is 16
    aes_tb$R_shape <- ifelse(is_mock, 1, 16 )
  }
  
  return(aes_tb)
}

###### get_default_palette() ##################################################################
# Returns vector of default colors for dotplot color & fill aesthetics. Colors were chosen to be 
# dark and distinct, though the colors become more similar as the number of visualized samples 
# increases.
#
# CALLS HELPERS: NA
# CALLED IN: check_plot_aesthetics()
#
# ARGUMENTS: none
#
# OUTPUT: 
#     default_palette = vector storing 30 default colors for dotplot color & fill aesthetics
get_default_palette <- function(){
  
  #6 colors per row: red, blue, green, orange/yellow, purple, brown
  # 30 colors total
  default_palette <- c("firebrick", "cornflowerblue", "olivedrab", "goldenrod", "mediumpurple", "tan4",
                      "tomato3", "steelblue1", "seagreen3", "darkorange", "darkorchid", "burlywood4",
                      "indianred1", "royalblue3", "palegreen4", "coral", "purple1", "peru", 
                      "firebrick1", "deepskyblue", "darkseagreen", "chocolate1", "palevioletred1", "tan",  
                      "darkred", "slateblue3", "springgreen", "darkgoldenrod", "plum", "wheat4")
  
  return(default_palette)
}

###### order_alpha() ##################################################################
# Generate alphabetical levels for a specific column (for plotting purposes)
#
# CALLS HELPERS: NA
# CALLED IN: summarize_off_targets()
#
# ARGUMENTS:
#   data_tb = any data frame
#   colname = data_tb column name to save as factor with sorted levels
#   decreasing_bool = logical indicating whether the alphanumeric sort is decreasing
#
# OUTPUT:
#   ordered_tb = returns the data_tb with the colname values saved as factors with alphanumeric sorted 
#                levels
order_alpha <- function(data_tb, colname, decreasing_bool){
  
  ordered_tb <- data_tb[str_order(data_tb[,colname], decreasing = decreasing_bool,
                                  numeric = TRUE),]
  
  ordered_tb[,colname] <- factor(ordered_tb[,colname], 
                                 levels = unique(ordered_tb[,colname]), ordered = TRUE)
  return(ordered_tb)
}


###### get_aes_scale_values_for_dotplot() ##################################################################
#Takes a data frame containing all information necessary to plot the editing frequency dotplot and 
# generates the list of aesthetics (color, fill, shape) to pass to scale_manual when generating dotplot.
#
# CALLS HELPERS: NA
# CALLED IN: summarize_off_targets()
#
# ARGUMENTS:
#   plotting_tb = data frame containing editing frequencies and target sequences to be plotted in dotplot
#
# OUTPUT:
#   aes_val_list = list of dotplot aesthetics scale values (color, fill, shape)
get_aes_scale_values_for_dotplot <- function(plotting_tb){
  
  #Generate color scale values
  color_values <- plotting_tb$R_color
  names(color_values) <- plotting_tb$group
  color_values <- color_values[which(!duplicated(names(color_values)))]
  
  color <- list("Group", color_values)
  
  #Generate fill scale values
  fill_values <- plotting_tb$R_fill
  names(fill_values) <- plotting_tb$group
  fill_values <- fill_values[which(!duplicated(names(fill_values)))]
  
  fill <- list("Group", fill_values)
  
  #Generate shape scale values
  shape_values <- plotting_tb$R_shape
  names(shape_values) <- plotting_tb$group
  shape_values <- shape_values[which(!duplicated(names(shape_values)))]
  
  shape <- list("Group", shape_values)
  
  #save all scale value lists in aes_val_list
  aes_val_list <- list("color_scale_val" = color,
                       "fill_scale_val" = fill,
                       "shape_scale_val" = shape)
  
  return(aes_val_list)
}


###### get_heatmap_legend_values() ##################################################################
get_heatmap_legend_values <- function(total_read_vector){
  
  #calculate legend breaks and values for read coverage legend
  max_reads <- max(total_read_vector, na.rm = TRUE)
  max_log10 <- round(log10(max_reads), digits = 0)
  max_legend_val <- round(max_reads, digits = -max_log10) + 10^max_log10
  legend_breaks_full <- seq(from = 0, to = max_legend_val, by = 10^(max_log10 - 1))
  smallest_max_legend_vals <- which(legend_breaks_full > max_reads)[1:2]
  
  #calculate the best legend label increments such that:
  # -there are at >= 5 labels
  # -the labels encompass 10^(max_log10 - 1) to at least the max_reads
  max_legend_val_idx <- data.frame(max_legend_val = rep(smallest_max_legend_vals, each = 11),
                                   factor = rep(seq(1,11), times = length(smallest_max_legend_vals))) %>%
    mutate(divisible_by = max_legend_val%%factor == 0)
  
  max_legend_val_idx$last_idx <- mapply(function(max_legend_val, factor) tail( seq(2, max_legend_val, by = factor), 1),
                                        max_legend_val_idx$max_legend_val, max_legend_val_idx$factor)
  max_legend_val_idx$n_labels <- mapply(function(max_legend_val, factor) length(seq(2, max_legend_val, by = factor)),
                                        max_legend_val_idx$max_legend_val, max_legend_val_idx$factor)
  
  max_legend_val_idx <- max_legend_val_idx %>%
    mutate(pass_n_labels = ifelse((n_labels == last_idx) | (n_labels >= 4 & n_labels <= 8), TRUE, FALSE)) %>%
    filter(last_idx >= smallest_max_legend_vals[1]) %>%
    filter( pass_n_labels ) %>%
    filter(factor == max(factor)) %>%
    filter(max_legend_val == min(max_legend_val))

  legend_breaks <- legend_breaks_full[c(1, seq(2, max_legend_val_idx$max_legend_val, 
                                               by = max_legend_val_idx$factor))]
  
  return(legend_breaks)
}


###### make_compiled_OT_editing_dotplot() ##################################################################
#Takes a summary table with all samples, all off-targets, and all editing outcomes and 
# generates editing summary dotplot. Also takes fill and color parameters for ggplot2. (The off-targets 
# are in the same order as the dotplot so that they are aligned when displayed together.)
# Returns a dotplot that is meant to be placed in a composite graph with a coverage heatmap.
#
# CALLS HELPERS: NA
# CALLED IN: summarize_off_targets()
#
# ARGUMENTS:
#   summary_tb = data frame containing read counts for each target and sample
#   scale_size_by_editing_freq = logical, whether or not to separate geom_points by size according to read coverage
#                                in the editing scatterplot
#   fill = list containing c(name, values) for scale_fill_manual
#   color = list containing c(name, values) for scale_color_manual
#   shape = list containing c(name, values) for scale_shape_manual
#   size = list containing aesthetic values for size of scatterplot/dotplot points
#   guide_font_size = font size of guides/targets 
#   editing_freq_scale = editing frequency log10 scale
#
# OUTPUT:
#   dotplot = dotplot of editing frequency for each target across samples
make_compiled_OT_editing_dotplot <- function(summary_tb, scale_size_by_editing_freq,
                                             fill, color, shape, size,
                                             guide_font_size, editing_freq_scale){
  dotplot <- ggplot(data = summary_tb,
                    aes(x = name_seq,
                        y = frequency)) 
  
  #generate jittered dotplot depending on whether scale_size_by_editing_freq == TRUE
  if(scale_size_by_editing_freq){
    dotplot <- dotplot +
      geom_jitter(aes(fill = group,
                      color = group,
                      shape = group,
                      size = R_point_size),
                  width = 0.1,
                  height = 0) +
      scale_size_manual(name = size[[1]],
                        values = size[[2]],
                        labels = size[[3]],
                        guide = guide_legend(ncol = 1))
  }else{
    
    dotplot <- dotplot + 
      geom_jitter(aes(fill = group,
                      color = group,
                      shape = group),
                  size = summary_tb$R_point_size[1],
                  width = 0.1,
                  height = 0) +
      guides(size = FALSE)
  }
  
  
  dotplot <- dotplot +
    xlab("") +
    ylab("% Editing Frequency\n") + 
    scale_y_continuous(position = "right", trans="log10",
                         limits = c(editing_freq_scale[1], 100),
                         breaks = editing_freq_scale,
                         labels = c(0, editing_freq_scale[2:(length(editing_freq_scale)-2)], 10, 100)) +
    coord_flip() +
    scale_x_discrete(limits = rev(levels(summary_tb$name_seq)),
                     labels = rev(levels(summary_tb$name_seq)),
                     breaks = rev(levels(summary_tb$name_seq))) +
    scale_fill_manual(name = fill[[1]],
                      values = fill[[2]],
                      guide = guide_legend(ncol = 1)) +
    scale_color_manual(name = color[[1]],
                       values = color[[2]],
                       guide = guide_legend(ncol = 1)) +
    scale_shape_manual(name = shape[[1]],
                values = shape[[2]],
                guide = guide_legend(ncol = 1)) + 
    theme_classic() +
    theme(axis.text.y = element_text(family = "Courier" , size = guide_font_size))
  
  return(dotplot)
}


###### make_compiled_summary_OT_editing_boxplot() ##################################################################
#Takes a summary table with all samples, all off-targets, and all editing outcomes and 
# generates editing summary boxplot displaying the statistics of the mock and edited mean/median. 
# Also takes fill and color parameters for ggplot2. (The off-targets are in the same order as the dotplot so 
# that they are aligned when displayed together.)
# Returns a dotplot that is meant to be placed in a composite graph with a coverage heatmap.
#
# CALLS HELPERS: NA
# CALLED IN: summarize_off_targets()
#
# ARGUMENTS:
#   summary_tb = data frame containing read counts for each target and sample
#   scale_size_by_editing_freq = logical, whether or not to separate geom_points by size according to read coverage
#                                in the editing scatterplot
#   fill = list containing c(name, values) for scale_fill_manual
#   color = list containing c(name, values) for scale_color_manual
#   shape = list containing c(name, values) for scale_shape_manual
#   size = list containing aesthetic values for size of scatterplot/dotplot points
#   guide_font_size = font size of guides/targets 
#   editing_freq_scale = editing frequency log10 scale
#
# OUTPUT:
#   dotplot = dotplot of editing frequency for each target across samples
make_compiled_summary_OT_editing_boxplot <- function(summary_tb, 
                                             #fill, color, shape, size,
                                             guide_font_size, editing_freq_scale){
  
  #Add "mean" for displaying mean in the legend
  summary_tb <- summary_tb %>%
    mutate(mean = "mean")
  
  boxplot <- ggplot(data = summary_tb,
                    aes(x = name_seq,
                        y = frequency,
                        fill = factor(condition))) +
    geom_boxplot(position = position_dodge(0.5),
                 alpha = 0.5,
                 width = 0.5,
                 color = "gray60") +
    stat_summary(fun.y = mean, 
                 geom = "point", 
                 size = 2,
                 color = "black",
                 show.legend = FALSE,
                 position = position_dodge(0.5),
                 aes(shape = mean)) +
    geom_point(alpha = 0,
               fill = "black",
               aes(shape = mean)) +
    xlab("") +
    ylab("% Editing Frequency\n") + 
    scale_y_continuous(position = "right", trans="log10",
                       limits = c(editing_freq_scale[1], 100),
                       breaks = editing_freq_scale,
                       labels = c(0, editing_freq_scale[2:(length(editing_freq_scale)-2)], 10, 100)) +
    coord_flip() +
    scale_x_discrete(limits = rev(levels(summary_tb$name_seq)),
                     labels = rev(levels(summary_tb$name_seq)),
                     breaks = rev(levels(summary_tb$name_seq))) +
    scale_fill_manual(name = "",
                      values = c("control" = "lightskyblue",
                                 "edited" = "lightcoral"), #"mean" = "black"
                      labels = c("control" = "Control/Mock",
                                 "edited" = "Edited"), #"mean" = "Mean % Editing"
                      guide = guide_legend(ncol = 1)) +
    scale_shape_manual(name = "",
                      values = c("mean" = 18),
                      labels = c("mean" = "Mean % Editing")) +
    theme_classic() +
    theme(axis.text.y = element_text(family = "Courier" , size = guide_font_size))  +
    guides(shape=guide_legend(title=NULL, override.aes = list(alpha = 1)))
  
  return(boxplot)
}


###### make_compiled_OT_coverage_heatmap() ##################################################################
#Takes a summary table with all samples, all off-targets, and all editing outcomes and generates read 
# coverage heatmap. (The off-targets are in the same order as the dotplot so that they are aligned when
# displayed together)
# Returns a heatmap that is meant to be placed in a composite graph with an editing dotplot.
#
# CALLS HELPERS: NA
# CALLED IN: summarize_off_targets()
#
# ARGUMENTS:
#   summary_tb = data frame containing read counts for each target and sample
#   guide_font_size = font size of guides/targets (not displayed in figure, mainly for formatting)
#   group_font_size = font size of groups/samples across top of heatmap
#   tile_font_size = font size of read counts displayed inside heatmap tiles
#
# OUTPUT:
#   heatmap = heatmap of read coverage for each target across samples
make_compiled_OT_coverage_heatmap <- function(summary_tb, guide_font_size,
                                              group_font_size, tile_font_size,
                                              legend_breaks){
  
  #generate heatmap
  heatmap <- ggplot(data = summary_tb,
                    aes(x = name_seq,
                        y = group)) +
    geom_tile(aes(fill = total_reads)) +
    geom_text(aes(label = gsub("NA", "",
                               format(ceiling(total_reads), 
                                     trim = FALSE, accuracy = 1, big.mark = ","))),
              size = tile_font_size,
              family = "Courier") +
    xlab("") +
    ylab("Total Reads per Sample\n") +
    scale_x_discrete(limits = rev(unique(summary_tb$name_seq)),
                     breaks = c(),
                     expand = c(0, 0)) +
    scale_y_discrete(position = "right",
                     limits = levels(summary_tb$group),
                     labels = c(gsub("[ ]{1}", "\n", levels(summary_tb$group))),
                     expand = c(0, 0)) +
    scale_fill_gradientn(name = "",
                         colours = c("grey95", "skyblue", "cornflowerblue"),
                         limits = c(legend_breaks[1], legend_breaks[length(legend_breaks)]),
                         breaks = legend_breaks,
                         labels = c("", as.character(comma(legend_breaks[2:length(legend_breaks)]))),
                         na.value = "white")  +
    coord_flip() +
    theme_classic() +
    theme(legend.position = "left",
          axis.text.y = element_text(family = "Courier" , size = guide_font_size),
          axis.text.x = element_text(colour = "grey50", size = group_font_size))
  
  return(heatmap)
}

###### make_composite_grobPlot() ##################################################################
### Generates a composite plot showing coverage as a heatmap on the left and % editing as 
### a dotplot on the right.
#
# CALLS HELPERS: NA
# CALLED IN: summarize_off_targets()
#
# ARGUMENTS:
#   heatmap = ggplot heatmap object to be plotted
#   dotplot = ggplot dotplot object to be plotted
#   heatmap_width = width of heatmap relative to dotplot_width
#   dotplot_width = width of dotplot relative to heatmap_width
#
# OUTPUT:
#   composite_grob = composite plot as grob (and displays the grob object)
make_composite_grobPlot <- function(heatmap, dotplot, heatmap_width, dotplot_width){
  
  #generate plot grobs & bind together
  g_heatmap <- ggplotGrob(heatmap)
  g_dotplot <- ggplotGrob(dotplot)
  
  grid.newpage()
  
  composite_grob <- plot_grid(heatmap, dotplot, ncol = 2, align = "h", axis = "bt", 
                              rel_widths = c(heatmap_width, dotplot_width))
  
  #visualize if in RStudio
  composite_grob 
  
  return(composite_grob)
}



###### save_composite_plot() ##################################################################
# Takes file_name (without extension), composite plot object, and width/height of saved plot (in inches)
# and saves the plot as .pdf and png
#
# CALLS HELPERS: NA
# CALLED IN: summarize_off_targets()
#
# ARGUMENTS:
#   file_name = file name of saved plots
#   composite_plot = composite plot object to be plotted
#   plot_width_in = width of saved plots in inches
#   plot_height_in = height of saved plots in inches
#
# OUTPUT: none
save_composite_plot <- function(file_name, composite_plot, plot_width_in, plot_height_in){
  
  #save composite plot as individual pdf
  # ggsave(paste(file_name, ".pdf", sep = ""), plot = composite_plot, 
  #        width = plot_width_in, height = plot_height_in,
  #        units = "in")
  
  #save composite plot as png
  ggsave(paste(file_name, ".png", sep = ""), plot = composite_plot, 
         width = plot_width_in, height = plot_height_in,
         units = "in")
  
}
